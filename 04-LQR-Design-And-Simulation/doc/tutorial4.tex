\documentclass[a4paper,11pt,headinclude=true,headsepline,parskip=half,DIV=13]{scrartcl}

% font, style, etc.
\usepackage[utf8]{inputenc} % defines
\usepackage[automark]{scrlayer-scrpage}
\usepackage{csquotes}
\usepackage{xspace} % proper space after macros with 0 args

% mathematics
\usepackage{amsmath}
\usepackage{amssymb}

% figures, tables, etc.
\usepackage{hyperref} %
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{pgf}
\usepackage{xcolor}
\usepackage{placeins} % -> floatbarrier
\usepackage{siunitx}  % -> handling of units
%\usepackage[printwatermark]{xwatermark}
%\newwatermark[allpages,color=red!50,angle=45,scale=1.8,xpos=0,ypos=0]{\textsf{DRAFT ONLY,NOT APPROVED}}

% code
\usepackage{listings}
\lstset{
language=Python, 
backgroundcolor = \color{light-gray},
basicstyle=\scriptsize\sffamily,
stringstyle=\color{orange},
breaklines=true,
numberstyle=\tiny\color{gray},
keywordstyle=\bfseries\color{dark-blue}\textit, % print keywords dark-blue
commentstyle=\color{dark-green}, % print comments dark-green
showstringspaces=false} % spacing between strings not showed

\newcommand{\listcode}[3]{\lstinputlisting[numbers=left,firstnumber=#1,firstline=#1,lastline=#2]{#3}}
\newcommand{\listcodeplot}[2]{\listcode{#1}{#2}{../sim/01_car_example_plotting.py}}
\newcommand{\listcodeanim}[2]{\listcode{#1}{#2}{../sim/02_car_example_animation.py}}

% others
\usepackage{acronym}
\usepackage{luacode}
\usepackage{soul}

% theorems
\newtheorem{defi}{Definition}[section]

% setup the appearance of links
\hypersetup{
    colorlinks = true, % false -> red box arround links (not very nice)
    linkcolor={blue!100!black},
    citecolor={blue!100!black},
    urlcolor={blue!100!black},
}

% manage glossaries
% Call makeglossaries on a command prompt after LaTeX compiling,
% the re-run LaTeX
\usepackage{glossaries}
\setacronymstyle{long-short}
\makeglossaries
\newacronym{ivp}{IVP}{initial value problem}
\newacronym{ode}{ODE}{ordinary differential equation}

% define shortcuts
\newcommand{\ad}{\mathrm{ad}}
\renewcommand{\d}{\mathrm{d}} % d vor differential forms
\newcommand{\NV}{{\cal N}\,}
\newcommand{\rang}{\mathrm{rang}}
\newcommand{\im}{\mathrm{im}}
\newcommand{\spann}{\mathrm{span}}
\newcommand{\R}{\mathbb{R}} %  set of real numbers
\newcommand{\py}{\emph{Python}\xspace}
\newcommand{\scipy}{\emph{SciPy}\xspace}
\newcommand{\numpy}{\emph{NumPy}\xspace}
\newcommand{\mpl}{\emph{Matplotlib}\xspace}
\newcommand{\uu}{\mathbf{u}}
\newcommand{\f}{\mathbf{f}}
\newcommand{\x}{\mathbf{x}}
\newcommand{\y}{\mathbf{y}}
\newcommand{\z}{\mathbf{z}}
\newcommand{\xZero}{\mathbf{x}_0}

% color definitions
\definecolor{light-gray}{gray}{0.95}
\definecolor{dark-blue}{rgb}{0, 0, 0.5}
\definecolor{dark-red}{rgb}{0.5, 0, 0}
\definecolor{dark-green}{rgb}{0, 0.5, 0}
\definecolor{gray}{rgb}{0.5, 0.5, 0.5}

% Avoid ugly indentations in footnotes.
\deffootnote[1em]{1em}{0em}{%
\textsuperscript{\thefootnotemark}%
}

\luadirect{dofile("luainputlisting.lua")}
\newcommand*\luainputlisting[2]{
    \luadirect{print_listing(\luastring{#1}, \luastring{#2})}
}

% ----------------------------------------------------------------------------
\subject{\py for simulation, animation and control}
\title{Design and Simulation of LQR Control}
\subtitle{An introductory tutorial for the design and implementation of LQR controllers for time-invariant and time-variant linear systems}
\author{Robert Heedt\thanks{Institute for Control Theory, Faculty of Electrical and Computer Engineering, Technische Universit√§t Dresden, Germany} \and Jan Winkler\footnotemark[1]}
\publishers{}
\date{\today}
% ----------------------------------------------------------------------------

% Headings
\pagestyle{scrheadings}
\ihead{\leftmark}
\chead{}
\ohead{Page \pagemark}
\ifoot{}
\cfoot{Python Control Tutorial 4}
\ofoot{}

\begin{document}

\maketitle




\tableofcontents

\newpage

\section{Introduction}
The goal of this tutorial is to teach the usage of the programming language \py as a tool for developing and simulating control systems.
The following topics are covered:
\begin{itemize}
    \item Flatness based feedforward control using existing trajectory generators
    \item Feedback control using LQR for linear time-invariant (LTI) system
    \item Demonstration of problematic situations
    \item Feedback control using LQR linear time-variant (LTV) system
\end{itemize}
Later in this tutorial this process is applied to design control strategies for the cart-pole system from a previous tutorial.

\section{Implementing the System}
In order to demonstrate the design methods discussed in the following, a simple academic example from \hl{??} will be used.
The system state~$x=(x_1, x_2)$ has two components and the scalar input is called~$u$.
Written in state-space-form, the system equation then is:
\begin{equation}
\dot x = F(x, u) = 
\begin{pmatrix}
a \sin(x_2)\\
-x_1^2+u\\
\end{pmatrix}\,.
\label{eq:academic_example_ss}
\end{equation}
Later, the jacobians
\begin{equation}
A^*(x^*, u^*) := \left.\frac{\partial F}{\partial x}\right\vert_{(x^*, u^*)}= \begin{pmatrix}0 & a \cos(x^*_2)\\-2 x^*_1 & 0\end{pmatrix}
\label{eq:jac_A}
\end{equation}
and
\begin{equation}
B^*(x^*, u^*) := \left.\frac{\partial F}{\partial u}\right\vert_{(x^*, u^*)}= \begin{pmatrix}0 \\ 1\end{pmatrix}
\label{eq:jac_B}
\end{equation}
will also be needed.

Implementing this system in Python then simply means expressing these terms as functions containing these computations. 
\luainputlisting{../sim/01_lqr.py}{defsystem}
Notable are mainly the usage of NumPy arrays for all vectors and the \lstinline{Parameters} class, please refer to a previous tutorial if unsure about these aspects.

\section{Trajectory Planning and Feedforward}

Similar to previous tutorials, feedforward control design can be simplified significantly by exploiting the flatness property of this system.
Specifically, the flat output is~$y=x_1$.
Recall, this means a desired trajectory $t \mapsto x_1^*(t)$ can be freely chosen (as long as it is sufficiently often differentiable).
Then, the trajectories for all other system variables (states and inputs) is calculated analytically without integration.

To this effect, the first system equation in~\eqref{eq:academic_example_ss} is solved for~$x_2$, yielding
\begin{equation}
x_2 = \arcsin\left(\frac{\dot x_1}{a}\right)
\label{eq:flatness_x2}
\end{equation}
which also introduces the constraint~$\forall t: |\dot x_1(t)| \leq |a|$ to trajectory planning.

After differentiating~\eqref{eq:flatness_x2} w.\,r.\,t.\ time, resulting in
$$
\dot x_2 = \frac{\ddot x_1}{\sqrt{a^2-\dot x_1^2}}\,,
$$
a term for $u$ is obtained by solving the second component of~\eqref{eq:academic_example_ss}:
$$
u = \dot x_2 + x_1^2 =  \frac{\ddot x_1}{\sqrt{a^2-\dot x_1^2}} + x_1^2\, .
$$
For the \py implementation, the trajectory planner from a previous tutorial is reused to obtain a polynomial that transitions from~$y(t_0) = y_0$ to~$y(t_f) = y_f$.
This function is then evaluated at the time values stored in vector \lstinline{t_traj}.
\luainputlisting{../sim/01_lqr.py}{plantraj}
The previously derived formulas are then translated into NumPy operations to obtain the values for~$x_2$ and~$u$ at every time step.
\luainputlisting{../sim/01_lqr.py}{flatness}

\section{Reminder: Linear Time Invariant Systems}
Before an LQR controller can be designed, the system in question must be linear.
As a rough approximation, Taylor linearization is used to obtain a linear time-invariant (LTI) system which is valid in the proximity to the operating point $(x^*, u^*)$.
In new coordinates $\tilde x=x - x^*$ and $\tilde u = u - u^*$ as well as by defining~$A:=A^*(x^*,u^*)$ and~$B:=B^*(x^*,u^*)$, the new state-space-form is then
$$
\dot{\tilde x}(t) = A \tilde x(t) + B \tilde u(t)\, .
$$
In \py, the operating point is defined by a time $t^*$ along the planned trajectory.
The corresponding array index is first determined and then used to get the values~$(x^*, u^*)$, with which the system matrices are computed.
\luainputlisting{../sim/01_lqr.py}{linsys}

Now an LQR controller will be designed by the book.
This means defining a cost-function
$$
J = \int_0^\infty \tilde x^T(t) Q x(t) + \tilde u^T(t) R u(t) \, \mathrm d t
$$
with the tuning matrices $Q$ and $R$ usually chosen as diagonal.
Minimizing this function leads to the algebraic Riccati equation
$$
P A + A^T P - P B R^{-1} B^T P + Q = 0
$$
having to be solved for $P$.
In \py the SciPy package fortunately contains the routine \lstinline{solve_continuous_are} which does exactly that.

The cost function then is minimal if a constant state feedback~$\tilde u = - K \tilde x$ is applied, with
$$
K = \begin{pmatrix} k_1 & k_2 \end{pmatrix} = R^{-1} B^T P\, .
$$
These computations -- save for the applying the actual control law, which happens in the main simulation loop -- can now be compactly written as
\luainputlisting{../sim/01_lqr.py}{solveare}

Now it is time to look at some simulation results.
Shown in Figure~\ref{fig:fig1} on the left side is the combination of feedforward control and feedback control, designed for a system linearized around the planned trajectory values at $t^*=0$.
The initial state~$x(0)$ is slightly offset from the planned initial position~$x^*(0)$, but the controller manages to track the trajectory anyway.

However, this choice of linearization point was arbitrary and lucky.
When e.\,g.\ $t^*=5$ is picked instead, the closed loop system immediately starts moving away from the reference value and tracking capability is lost.
This is demonstrated on the right side of Figure~\ref{fig:fig1}.

\begin{figure}[ht]
    \centering
    \includegraphics[scale=1]{img/fig1.pdf}
    \caption{Closed loop simulation of trajectory tracking, controller designed for different linearization points}
    \label{fig:fig1}
\end{figure}

In fact, simply sticking to $t^*=0$ also does not work.
For other reference trajectories, e.\,g.\ for~$y(0)=2$ and~$y(10)=-2$ (the reverse trajectory if you will), choosing the same linearization time fails.
In that case~$t^*=10$ must instead be used.

It appears that tracking arbitrary trajectories with this approach is not feasible, since the linearized system can never sufficiently represent the more involved non-linear dynamics and a "one size fits all" constant state feedback is therefore bound to fail.

One might be tempted to improve the controller by simply re-linearizing the system and re-computing the feedback matrix at every time step.
For this specific case this approach actually works and is very easy to implement when a normal LQR controller already exists.
Simulation results are shown in Figure~\ref{fig:fig2}, along with a plot of the changing feedback matrix entries over time.

\begin{figure}[ht]
    \centering
    \includegraphics[scale=1]{img/fig2.pdf}
    \caption{Closed loop simulation of trajectory tracking, controller retuned for linearized system at every time step}
    \label{fig:fig2}
\end{figure}

Remember this is dangerous territory though.
No stability guarantees can be made here, because this ad-hoc solution corresponds to a linear system approximation with time-variant system matrices
$$
\dot{\tilde x}(t) = A(t)\tilde x(t) + B(t) u(t)\, .
$$
For a linear time-variant system, the closed loop system matrix $A(t) - B(t)K(t)$ must only contain eigenvalues $s$ with $\mathrm{Re}\,(s) < 0$, but also be \textbf{constant} in order for the closed loop to be stable!
This property is not ensured in this controller design, using it is therefore not recommended.

\printglossaries

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End: